{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v12aczJCbpa"
      },
      "source": [
        "# Loading modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpJxtuSsCnMm"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import scipy.ndimage as ndimage \n",
        "import skimage \n",
        "from scipy import stats "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlngLkWzB_kM"
      },
      "source": [
        "# Centers Initialization \n",
        "PeakFinder uses the histogram of the image to find the initial centers of the grayscales. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ogfmh0MBogL"
      },
      "source": [
        "import cmath \n",
        "class PeakFinder:\n",
        "  def __init__(self, img, mincenters): \n",
        "    self.hist, _  = np.histogram(img, bins=256)\n",
        "    self.s1 = [i for i in range(1,255) if self.hist[i] > max(self.hist[i-1], self.hist[i+1])]\n",
        "    self.s2 = [i for i in range(1, len(self.s1)-1) if self.hist[self.s1[i]] > max(self.hist[self.s1[i-1]],self.hist[self.s1[i+1]])]\n",
        "    self.s3 = [x for x in self.s2  if x >= 2.5/100 * self.hist.argmax()]\n",
        "    lst = []\n",
        "    i = j = 0\n",
        "    while j < len(self.s3): \n",
        "      while j < len(self.s3) and abs(self.s3[i]- self.s3[j]) < 15:\n",
        "        j += 1 \n",
        "      lst.append(self.s3[i:j].copy())\n",
        "      i = j \n",
        "    self.s4 = [max(e) for e in lst]\n",
        "    set1 = {x for x in self.s4 if cmath.polar(complex(x,self.hist[x]))[1] > cmath.pi/6} \n",
        "    set2 = {x for x, y in zip(self.s4, self.s4[1:]) if abs(complex(x,self.hist[x])- complex(y, self.hist[y])) >= 40 }\n",
        "    self.s5 = sorted(set1|set2)\n",
        "    self.all = sorted([self.s1, self.s2, self.s3, self.s4, self.s5], key = len)\n",
        "    for e in self.all:\n",
        "      if len(e) >= mincenters:\n",
        "        self.res = e\n",
        "        self.all.insert(0,e)\n",
        "        break \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm5X6lh1Cw1i"
      },
      "source": [
        "# HGMM\n",
        "\n",
        "Apply EM with GMM on the histogram of a gray scale image to obtain an initial Segmentation. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiHfAu18CuXS"
      },
      "source": [
        "class EMGMM:\n",
        "  def __init__(self, priors, means, vars, min_var = 1e-3, var_regularizer = 1e-3, epsilone = 1e-5, \n",
        "               max_iterations = 1000):\n",
        "    self.priors = np.array(priors)\n",
        "    self.means = np.array(means, dtype = np.float)\n",
        "    self.vars = np.array(vars, dtype = np.float )\n",
        "    self.var_regularizer = var_regularizer \n",
        "    self.epsilone = epsilone \n",
        "    self.max_iterations = max_iterations\n",
        "    self.min_var = min_var \n",
        "  \n",
        "\n",
        "  def gamma(self):\n",
        "    res =  np.empty((self.hist.size, self.means.size))\n",
        "    data = np.arange(256)\n",
        "    for j in range(self.means.size):\n",
        "      res[:,j] = self.priors[j] * stats.norm.pdf(data, loc = self.means[j],\n",
        "                                                              scale = np.sqrt(self.vars[j]))\n",
        "\n",
        "    return res \n",
        "  def llk(self):\n",
        "    return (np.log(self.gamma().sum(axis = -1)) * self.hist).sum() / self.hist.sum()\n",
        "  \n",
        "  def e_step(self):\n",
        "    self.latent_distr = self.gamma()\n",
        "    self.latent_distr =  self.latent_distr / self.latent_distr.sum(axis =-1).reshape(-1,1)\n",
        "    self.expected_size = (self.hist.reshape(-1,1) * self.latent_distr).sum(axis = 0)\n",
        "\n",
        "  def m_step(self):\n",
        "    self.priors = self.expected_size / self.hist.sum()\n",
        "    self.means = self.hist.reshape(-1,1) * np.arange(256).reshape(-1,1) * self.latent_distr\n",
        "    self.means = self.means.sum(axis = 0) / self.expected_size\n",
        "    self.vars = self.latent_distr * ((np.arange(256).reshape(-1,1) - self.means)**2) * self.hist.reshape(-1,1)\n",
        "    self.vars = self.vars.sum(axis = 0) / self.expected_size\n",
        "    self.vars[self.vars < self.min_var] = self.var_regularizer\n",
        "  \n",
        "\n",
        "  def next(self, new_llk):\n",
        "    self.cur_iter += 1 \n",
        "    if(abs(self.old_llk - new_llk) < self.epsilone):\n",
        "      self.stop = True \n",
        "      self.sucess = True \n",
        "    elif self.cur_iter >= self.max_iterations:\n",
        "      self.stop = True \n",
        "      self.sucess = False \n",
        "    \n",
        "  def fit(self, hist):\n",
        "    self.hist = hist \n",
        "    self.cur_iter = 0 \n",
        "    new_llk = self.llk()\n",
        "    self.stop = False \n",
        "    while not self.stop: \n",
        "      self.old_llk = new_llk\n",
        "      self.e_step()\n",
        "      self.m_step()\n",
        "      new_llk = self.llk()\n",
        "      self.next(new_llk) \n",
        "  \n",
        "  def predict(self, data):\n",
        "    lst = []\n",
        "    #for mu, sigma in zip(self.means, self.vars):\n",
        "    #  lst.append(stats.norm(data, loc = mu, scale = np.sqrt(sigma) ))\n",
        "    #a = np.stack(lst)\n",
        "    a = np.stack([stats.norm.pdf(data, loc = mu, scale= np.sqrt(sigma)) for mu, sigma in zip(self.means, self.vars)])\n",
        "    return a.argmax(axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxKcqntpDV6v"
      },
      "source": [
        "# Image Iterators\n",
        "Used To Traverse the image pixels in diverse orders "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBUsTPs9DuB-"
      },
      "source": [
        "## The base Class for ImageIterators\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8d7l4DxDPVQ"
      },
      "source": [
        "from collections.abc import Iterable \n",
        "class ImageIterator(Iterable):\n",
        "\n",
        "  def __init__(self, img, lbls = None):\n",
        "    self._image = img\n",
        "    self._labels = lbls \n",
        "\n",
        "  \n",
        "  @property\n",
        "  def shape(self):\n",
        "    return self._image.shape \n",
        "  \n",
        "  @property\n",
        "  def size(self):\n",
        "    return self._image.size "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfEcFytTEPCG"
      },
      "source": [
        "## Raster ImageIterator \n",
        "Traverse the pixels row by row column by colum up-down left-right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwftHoiTEN-p"
      },
      "source": [
        "class RasterImageIterator(ImageIterator):\n",
        "  def __iter__(self):\n",
        "    h, w  = self.shape \n",
        "    for y in range(h):\n",
        "      for x in range(w):\n",
        "        yield (y,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHq-IgpaEif3"
      },
      "source": [
        "## Intertwined Image Iterator\n",
        "\n",
        "Left-right for even rows\n",
        "Right-left for odd rows  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68a9fqDVEhOI"
      },
      "source": [
        "class IntertWinedImageIterator(ImageIterator):\n",
        "  def __iter__(self):\n",
        "    h, w = self.shape \n",
        "    x_start = 0 \n",
        "    x_end = w\n",
        "    x_step = 1 \n",
        "    for y in range(h):\n",
        "      for x in range(w) if y % 2 == 0 else reversed(range(w)):\n",
        "        yield (y,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBIotoXuE1nL"
      },
      "source": [
        "## Snail Curve Image Iterator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9RcY5aAEyhm"
      },
      "source": [
        "class SnailCurveImageIterator(ImageIterator):\n",
        "\n",
        "  def __iter__(self):\n",
        "    if 'cache' in self.__dict__:\n",
        "      yield from self.cache \n",
        "    else:\n",
        "      self.cache = []\n",
        "      h, w = self.shape  \n",
        "      start_y = start_x = 0 \n",
        "      end_y = h - 1\n",
        "      end_x = w - 1\n",
        "      while len(self.cache) < w * h:\n",
        "        y = start_y\n",
        "        for x in range(start_x, end_x +1):\n",
        "          self.cache.append((y,x))\n",
        "          yield (y,x)\n",
        "        start_y += 1 \n",
        "\n",
        "        x = end_x \n",
        "        for y in range(start_y, end_y + 1):\n",
        "          self.cache.append((y,x))\n",
        "          yield (y,x)\n",
        "        end_x -= 1 \n",
        "\n",
        "        y = end_y \n",
        "        for x in reversed(range(start_x, end_x +1 )):\n",
        "          self.cache.append((y,x))\n",
        "          yield (y,x)\n",
        "        end_y -= 1\n",
        "\n",
        "        x = start_x \n",
        "        for y in reversed(range(start_y, end_y + 1)):\n",
        "          self.cache.append((y,x))\n",
        "          yield (y,x)\n",
        "        start_x += 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FialJjsFLRp"
      },
      "source": [
        "## ZigZag Image Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzquxbJFGAS"
      },
      "source": [
        "class ZigZagImageIterator(ImageIterator):\n",
        "  def __iter__(self):\n",
        "    if 'cache' in self.__dict__:\n",
        "      yield from self.cache \n",
        "    else:\n",
        "      self.cache = []\n",
        "      h, w =  self.shape\n",
        "      line = h; column = w \n",
        "      for k in range(line+ column):\n",
        "        if  k % 2 != 0:\n",
        "          x = min(k, column - 1)\n",
        "          while x >= max(0, k- line +1):\n",
        "            y = k- x \n",
        "            self.cache.append((y,x))\n",
        "            yield (y,x)\n",
        "            x -= 1 \n",
        "        else: \n",
        "          y = min(k, line -1)\n",
        "          while y >= max(0, k - column +1):\n",
        "            x = k - y \n",
        "            self.cache.append((y,x))\n",
        "            yield (y,x)\n",
        "            y -= 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlpvQBUEGTAG"
      },
      "source": [
        "## Mappping Classes \n",
        "Maps N-d Points to a scalar using diverse space fillilg curves (ZCurves and HilbertCurves)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xl5RYGYFRWC"
      },
      "source": [
        "class ZMapping:\n",
        "  @staticmethod\n",
        "  def _ZIndex(pt, nbits):\n",
        "    \"\"\"\n",
        "    Computes  the z-index of a multi-dimensional point pt \n",
        "    \"\"\"\n",
        "    z = 0 \n",
        "    mask = 1<<nbits -1 \n",
        "    for i in range(nbits):\n",
        "      for coord in pt:\n",
        "        z += coord& mask\n",
        "        z <<= 1 \n",
        "      mask >>= 1 \n",
        "    return z\n",
        "\n",
        "  @staticmethod\n",
        "  def _ZPointAt(zidx, dim, nbits):\n",
        "    \"\"\"\n",
        "    Computes the coordinate of a point in the Z curve Given its index \n",
        "    \"\"\"\n",
        "    pt = [0] * dim\n",
        "    mask = 1 << (dim * nbits -1)\n",
        "    for j in range(nbits):\n",
        "      for i in range(dim):\n",
        "        pt[i] <<= 1 \n",
        "        pt[i] += int((zidx & mask)> 0)\n",
        "        mask >>= 1 \n",
        "    return tuple(pt)\n",
        "\n",
        "  def __init__(self, dim, nbits):\n",
        "    self.dim = dim \n",
        "    self.nbits = nbits \n",
        "  \n",
        "\n",
        "  def ZIndex(self, pt):\n",
        "    \"\"\"\n",
        "    Computes the Zindex of a given point of the curve \n",
        "    \"\"\"\n",
        "    return ZMapping._ZIndex(pt, self.nbits)\n",
        "  \n",
        "  def ZPointAt(self, zidx):\n",
        "    \"\"\"\n",
        "    Compute a Point From its Zindex \n",
        "    \"\"\"\n",
        "    return ZMapping._ZPointAt(zidx, self.dim, self.nbits)\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a7upQlMGrBj"
      },
      "source": [
        "class HilbertMapping:\n",
        "  @staticmethod\n",
        "  def HilbertAxes(transposedIndex, bits):\n",
        "    X = list(transposedIndex)\n",
        "    n = len(X)\n",
        "    N = 2 << (bits -1)\n",
        "    t = X[n-1] >> 1\n",
        "    for i in reversed(range(1, n)):\n",
        "      X[i] ^= X[i-1]\n",
        "    X[9] ^= t \n",
        "    Q = 2 \n",
        "    while Q != N:\n",
        "      P = Q - 1 \n",
        "      for i in reversed(range(1, n)):\n",
        "        if (X[i]&Q) != 0:\n",
        "          X[0] ^= P\n",
        "        else:\n",
        "          t = (X[0]^X[i])&P \n",
        "          X[0] ^= t \n",
        "          X[i] ^= t\n",
        "      Q <<= 1\n",
        "    return tuple(X) \n",
        "  \n",
        "  @staticmethod\n",
        "  def HilbertIndexTransposed(hilbertAxes, bits):\n",
        "    \n",
        "    X = list(hilbertAxes)\n",
        "    n = len(X)\n",
        "    M = 1 <<(bits-1)\n",
        "    Q = M\n",
        "    while Q > 1:\n",
        "      P = Q - 1 \n",
        "      for i in range(n):\n",
        "        if (X[i]&Q) != 0:\n",
        "          X[0] ^= P \n",
        "        else:\n",
        "          t = (X[0]^X[i]) & P \n",
        "          X[0] ^= t \n",
        "          X[i] ^= t \n",
        "      Q >>= 1 \n",
        "    for i in range(1, n):\n",
        "      X[i] ^= X[i-1]\n",
        "    \n",
        "    t = 0 \n",
        "    Q = M \n",
        "    while Q > 1: \n",
        "      if (X[n-1]& Q) != 0:\n",
        "        t ^= Q -1 \n",
        "      Q >>= 1 \n",
        "    for i in range(n): \n",
        "      X[i] ^= t \n",
        "    return tuple(X)\n",
        "\n",
        "  @staticmethod\n",
        "  def _HilberIndex(HilbertIndex, bits):\n",
        "    H = 0 \n",
        "    Mask = 1 << bits - 1 \n",
        "    for i in range(bits):\n",
        "      for j in HilbertIndex:\n",
        "        H += j& Mask\n",
        "        H <<= 1 \n",
        "      Mask >>= 1 \n",
        "    return H \n",
        "\n",
        "  @staticmethod\n",
        "  def TransposeHilbertIndex(HilbertIndex, bits, dimensions):\n",
        "    THilbert = [0] * dimensions\n",
        "    Mask = 1 << (bits * dimensions - 1)\n",
        "    for j in range(bits):\n",
        "      for i in range(dimensions):\n",
        "        THilbert[i] <<= 1 \n",
        "        THilbert[i] += int(HilbertIndex& Mask)\n",
        "        Mask >>= 1 \n",
        "    return tuple(THilbert) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __init__(self, dim, nbits):\n",
        "    self.dim = dim\n",
        "    self.nbits  = nbits \n",
        "\n",
        "  def HilbertIndex(self, pt):\n",
        "    t = HilbertMapping.HilbertIndexTransposed(pt, self.nbits)\n",
        "    return HilbertMapping._HilberIndex(t, self.nbits)\n",
        "\n",
        "  def HilbertCurveAt(hidx):\n",
        "    t = HilbertMapping.TransposedHilberIndex(hidx, self.nbits, self.dim)\n",
        "    return HilbertMapping.HilbertAxes(t, this.nbits)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdt0ntiSG76D"
      },
      "source": [
        "## Z2D Image iterator\n",
        "Uses a Zcurve filling the 2D pixel grid to traverse the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rcFSdAQG2W3"
      },
      "source": [
        "class Z2DImageIterator(ImageIterator):\n",
        "\n",
        "  def __init__(self, img, lbls = None):\n",
        "    super().__init__(img, lbls)\n",
        "    h, w = self.shape \n",
        "    self.cache = [(y,x) for y in range(h) for x in range(w)]\n",
        "    from math import log2, ceil\n",
        "    nbits = int(ceil(log2(max(h,w)))) \n",
        "    map = ZMapping(2, nbits)\n",
        "    self.cache.sort(key = map.ZIndex)\n",
        "  \n",
        "  def __iter__(self):\n",
        "    yield from self.cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRpSxnLqPX1x"
      },
      "source": [
        "## Hilbert 2D Image Iterator \n",
        "Uses a 2D space Hilbert Filling curve to traverse the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPP3gRNbHRO4"
      },
      "source": [
        "class Hilbert2DImageIterator(ImageIterator):\n",
        "\n",
        "  def __init__(self, img, lbls = None):\n",
        "    super().__init__(img, lbls)\n",
        "    h, w = self.shape \n",
        "    self.cache = [(y,x) for y in range(h) for x in range(w)]\n",
        "    from math import log2, ceil\n",
        "    nbits = int(ceil(log2(max(h,w)))) \n",
        "    map = HilbertMapping(2, nbits)\n",
        "    self.cache.sort(key = map.HilbertIndex)\n",
        "  \n",
        "  def __iter__(self):\n",
        "    yield from self.cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YOpXncKP4lh"
      },
      "source": [
        "## Code Image Iterator\n",
        "Iterates over neighborhood independent pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0MblLoTP2iz"
      },
      "source": [
        "class CodeImageIterator(ImageIterator):\n",
        "  def __init__(self, pos, step, img, lbls = None ):\n",
        "    super().__init__(img, lbls)\n",
        "    self.y, self.x = pos \n",
        "    self.stepy, self.stepx = step \n",
        "  \n",
        "  def __iter__(self):\n",
        "    h, w = self.shape\n",
        "    for y in range(self.y, h, self.stepy):\n",
        "      for x in range(self.x, w, self.stepx):\n",
        "        yield (y,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQiyI2XIQGFF"
      },
      "source": [
        "## Codes Image Iterator \n",
        "Splits the image into neighborhood independent subsets 'Codes' and iterates over the codes one by one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9GAfElMQE8j"
      },
      "source": [
        "class CodesImageIterator(ImageIterator):\n",
        "  def __init__(self, steps, imgs, lbls = None):\n",
        "    super().__init__(imgs, lbls)\n",
        "    self.stepy, self.stepx = steps\n",
        "\n",
        "  def __iter__(self):\n",
        "    for y in range(self.stepy):\n",
        "      for x in range(self.stepx):\n",
        "        yield from  CodeImageIterator((y,x), (self.stepy, self.stepx), self._image, self._labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzfI2BDiQd_f"
      },
      "source": [
        "## Z3D Image Iterator \n",
        "Uses a 3D Z filling curve based on (y,x, gray[y,x]) to traverse the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeKlMceLQcdh"
      },
      "source": [
        "class Z3DImageIterator(ImageIterator):\n",
        "  def __init__(self, img, lbls = None):\n",
        "    super().__init__(img, lbls)\n",
        "    h, w = self.shape \n",
        "    from math import ceil, log2\n",
        "    nbits = int(ceil(log2(max(h,w,self._image.max()))))\n",
        "    map = ZMapping(3, nbits)\n",
        "    b = 2 ** nbits \n",
        "    stepx = b // w\n",
        "    stepy = b//h \n",
        "    stepi = b // self._image.max()\n",
        "    self.cache = [(y,x) for y in range(h) for x in range(w)]\n",
        "    self.cache.sort(key = lambda p : map.ZIndex((p[0] * stepy,p[1] * stepx, self._image[p] * stepi)))\n",
        "  \n",
        "  def __iter__(self):\n",
        "    yield from self.cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OlGPDX0Q3Fs"
      },
      "source": [
        "## Hilbert 3D Image iterator  \n",
        "Uses a 3D  Hilbert Space filling curve "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n_yrKRgQ2QP"
      },
      "source": [
        "class Hilbert3DImageIterator(ImageIterator):\n",
        "  def __init__(self, img, lbls = None):\n",
        "    super().__init__(img, lbls)\n",
        "    h, w = self.shape \n",
        "    from math import ceil, log2\n",
        "    nbits = int(ceil(log2(max(h,w,self._image.max()))))\n",
        "    map = HilbertMapping(3, nbits)\n",
        "    b = 2 ** nbits \n",
        "    stepx = b // w\n",
        "    stepy = b//h \n",
        "    stepi = b // self._image.max()\n",
        "    self.cache = [(y,x) for y in range(h) for x in range(w)]\n",
        "    self.cache.sort(key = lambda p : map.HilbertIndex((p[0] * stepy ,p[1] * stepx , self._image[p] * stepi)))\n",
        "  \n",
        "  def __iter__(self):\n",
        "    yield from self.cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THGbY2m0mmVD"
      },
      "source": [
        "# Utility functions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwfiowvORSpr"
      },
      "source": [
        "return the 8-immediate neighbors of a pixel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD9EcfNaRLE8"
      },
      "source": [
        "def get8neighbors(y,x):\n",
        "  s = {(y+i, x+j) for i in range(-1, 2) for j in range(-1, 2)}\n",
        "  return s- {(y,x)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_O6ka7TxNt"
      },
      "source": [
        "reads an image from a file a ndarray "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJbP96clT2vz"
      },
      "source": [
        "def imread(path):\n",
        "  img = plt.imread(path)\n",
        "  if img.ndim > 2:\n",
        "    img = img[:,:,0]\n",
        "  if img.dtype is not np.uint8:\n",
        "    img = img * 255\n",
        "    img = img.round()\n",
        "  return img.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwqbRnfJRZnR"
      },
      "source": [
        "# Markov Random Field Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmUol-zNRgP-"
      },
      "source": [
        "## Offline MRF Map\n",
        "Used to descripe MRF Field where the stats are update in offline mode (after the whole image is traversed)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmp7f6n_RXxr"
      },
      "source": [
        "class OfflineMRFMap:\n",
        "  def __init__(self, img, lbls, priors, interaction, minvar = 30, var_regularizer = 30):\n",
        "    assert img.shape == lbls.shape \n",
        "    assert lbls.max() + 1 == priors.size == interaction.shape[0] == interaction.shape[1] \n",
        "    h, w = img.shape \n",
        "    self._minvar = minvar \n",
        "    self._varRegularizer = var_regularizer\n",
        "    self._priors = priors \n",
        "    self._interaction = interaction \n",
        "    self._image = np.zeros((h+2, w+2), img.dtype)\n",
        "    self._image[1:-1, 1:-1] = img \n",
        "    x = np.zeros((h+2, w+2), lbls.dtype)\n",
        "    x[1:-1, 1:-1] = lbls \n",
        "    self._labelCount = lbls.max() + 1 \n",
        "    self._next_x = x.copy()\n",
        "    self.init_stats()\n",
        "  \n",
        "  @staticmethod\n",
        "  def adapt(y,x):\n",
        "    return (y+1, x+1)\n",
        " \n",
        "  @property \n",
        "  def shape(self):\n",
        "    h, w = self._image.shape \n",
        "    return (h-2,w-2)\n",
        " \n",
        "  def __iter__(self):\n",
        "    h, w = self.shape \n",
        "    for y in range(h):\n",
        "      for x in range(w):\n",
        "        yield OfflineMRFMap.adapt(y,x)\n",
        "  \n",
        "  def init_stats(self):\n",
        "    self._cur_x = self._next_x.copy()\n",
        "    self._globalW = 0 \n",
        "    self._lbl_Hist = np.zeros((self._labelCount,), dtype = np.int)\n",
        "    self._sums = np.zeros((self._labelCount,), dtype = np.double)\n",
        "    self._sqSums = self._sums.copy()\n",
        "    self._localPotentials = np.zeros_like(self._image)\n",
        "    for y, x in self:\n",
        "      cur_seg = self._cur_x[y,x]\n",
        "      cur_gray = self._image[y,x]\n",
        "      self._lbl_Hist[cur_seg] += 1 \n",
        "      self._sums[cur_seg] += cur_gray\n",
        "      self._sqSums[cur_seg] += cur_gray **2 \n",
        "      self._localPotentials[y,x] = self._priors[cur_seg]\n",
        "      for ny, nx in get8neighbors(y,x):\n",
        "        n_seg = self._cur_x[ny, nx]\n",
        "        self._localPotentials[y,x] += self._interaction[cur_seg, n_seg]\n",
        "      self._globalW += self._localPotentials[y,x] + self._conditionalLocalW(y,x)\n",
        "      #logging.info(\" globalW = {}\".format(self._globalW))\n",
        "     \n",
        "  def mean(self, lbl):\n",
        "    return self._sums[lbl] / self._lbl_Hist[lbl]\n",
        "  \n",
        "  def variance(self, lbl):\n",
        "    sqMean = self.mean(lbl)**2 \n",
        "    var = self._sqSums[lbl] / self._lbl_Hist[lbl] - sqMean \n",
        "    return var if var >= self._minvar else var + self._varRegularizer\n",
        " \n",
        "  def _conditionalLocalW(self, y,x):\n",
        "    lbl = self._cur_x[y,x]\n",
        "    sigma = self.variance(lbl)\n",
        "    mu = self.mean(lbl)\n",
        "    y = self._image[y,x]\n",
        "    return (y - mu)**2 /(2* sigma) + np.log(np.sqrt(sigma))\n",
        "  def conditionalLocalW(self, y, x):\n",
        "    return self._conditionalLocalW(self, * OfflineMRFMap.adapt(y,x))\n",
        " \n",
        "  def localPriorW(self, y, x):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._localPotentials[y,x]\n",
        " \n",
        "  def _localPotential(self, y,x, lbl):\n",
        "    if lbl == self._cur_x[y,x]:\n",
        "      return self._localPotentials[y,x]\n",
        "    else:\n",
        "      lP = self._priors[lbl]\n",
        "      for ny, nx in get8neighbors(y,x):\n",
        "        nlbl = self._cur_x[ny, nx]\n",
        "        lP += self._interaction[lbl, nlbl]\n",
        "      return lP\n",
        " \n",
        "  def localPotential(self, y, x, lbl):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._localPotential(y,x, lbl)\n",
        " \n",
        " \n",
        "  def localW(self, y, x, lbl):\n",
        "    y, x = self.adapt(y,x)\n",
        "    lW = self._localPotential(y,x, lbl)\n",
        "    cur_lbl = self._cur_x[y,x]\n",
        "    y = self._image[y,x]\n",
        "    mu = self.mean(lbl)\n",
        "    sigma = self.variance(lbl)\n",
        "    lW += (y - mu)**2 / (2*sigma) + np.log(np.sqrt(sigma))\n",
        "    return lW\n",
        " \n",
        "  def localFit(self, y, x, lbl):\n",
        "    return np.exp(-self.localW(y,x, lbl))\n",
        "  \n",
        "  def changeLabel(self, y, x, lbl):\n",
        "    y, x = self.adapt(y,x)\n",
        "    self._next_x[y,x] = lbl \n",
        "  \n",
        "  def label(self, y, x):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._cur_x[y,x]\n",
        "  \n",
        "  @property\n",
        "  def globalW(self):\n",
        "    return self._globalW\n",
        " \n",
        "  @property\n",
        "  def globalFit(self):\n",
        "    return np.exp(- self.globalW / (self.size))\n",
        "  \n",
        "  @property\n",
        "  def size(self):\n",
        "    return (self._image.shape[0] -2) * (self._image.shape[1]-2)\n",
        "  \n",
        "  @property\n",
        "  def labels(self):\n",
        "    return self._next_x[1:-1, 1:-1].copy()\n",
        "  \n",
        "  @property\n",
        "  def labelCount(self):\n",
        "    return self._labelCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYFC81eAt5A_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OYGtvVkt4Ax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw_z8mZ0SCoa"
      },
      "source": [
        "## Online MRF Map\n",
        "\n",
        "Represents an MRF Field where the stats are updated online (after each side labeling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uJffwR7R3q6"
      },
      "source": [
        "class OnlineMRFMap:\n",
        " \n",
        "  def __init__(self, img, lbls, priors, interaction, minvar = 30, var_regularizer = 30):\n",
        "\n",
        "    assert img.shape == lbls.shape \n",
        "    assert lbls.max() + 1 == priors.size == interaction.shape[0] == interaction.shape[1] \n",
        "    h, w = img.shape \n",
        "    self._minvar = minvar \n",
        "    self._varRegularizer = var_regularizer\n",
        "    self._priors = priors \n",
        "    self._interaction = interaction \n",
        "    self._image = np.zeros((h+2, w+2), img.dtype)\n",
        "    self._image[1:-1, 1:-1] = img \n",
        "    x = np.zeros((h+2, w+2), lbls.dtype)\n",
        "    x[1:-1, 1:-1] = lbls \n",
        "    self._labelCount = lbls.max() + 1 \n",
        "    self._x = x\n",
        "    self.init_stats()\n",
        "    self._computeGlobalW()\n",
        " \n",
        "  @property\n",
        "  def globalW(self):\n",
        "    if self._updateGlobalW:\n",
        "      self._computeGlobalW()\n",
        "    return self._globalW\n",
        " \n",
        " \n",
        "  @property\n",
        "  def globalFit(self):\n",
        "    return np.exp(- self.globalW / (self.size))\n",
        " \n",
        "    \n",
        "  def label(self, y, x):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._x[y,x]\n",
        " \n",
        "  def localFit(self, y, x):\n",
        "    return np.exp(-self.localW(y,x))\n",
        " \n",
        "  def _computeGlobalW(self):\n",
        "    self._globalW = sum(self._localW(y,x) for y, x in self)\n",
        "    self._updateGlobalW = False \n",
        "    \n",
        "  \n",
        "  @staticmethod\n",
        "  def adapt(y,x):\n",
        "    return (y+1, x+1)\n",
        " \n",
        "  @property \n",
        "  def shape(self):\n",
        "    h, w = self._image.shape \n",
        "    return (h-2,w-2)\n",
        " \n",
        "  def __iter__(self):\n",
        "    h, w = self.shape \n",
        "    for y in range(h):\n",
        "      for x in range(w):\n",
        "        yield OnlineMRFMap.adapt(y,x)\n",
        "  \n",
        "  def init_stats(self):\n",
        "    self._lbl_Hist = np.zeros((self._labelCount,), dtype = np.int)\n",
        "    self._sums = np.zeros((self._labelCount,), dtype = np.double)\n",
        "    self._sqSums = self._sums.copy()\n",
        "    for y, x in self:\n",
        "      cur_seg = self._x[y,x]\n",
        "      cur_gray = self._image[y,x]\n",
        "      self._lbl_Hist[cur_seg] += 1 \n",
        "      self._sums[cur_seg] += cur_gray\n",
        "      self._sqSums[cur_seg] += cur_gray **2 \n",
        "      \n",
        " \n",
        "  def _updatestats(self,y, x, oldlbl, newlbl):\n",
        "    if oldlbl != newlbl:\n",
        "      self._updateGlobalW = True\n",
        "      g = self._image[y,x]\n",
        "      self._lbl_Hist[oldlbl] -= 1 \n",
        "      self._lbl_Hist[newlbl] += 1 \n",
        "      self._sums[oldlbl] -= g\n",
        "      self._sums[newlbl] += g \n",
        "      self._sqSums[oldlbl] -= g**2 \n",
        "      self._sqSums[newlbl] += g**2 \n",
        " \n",
        " \n",
        "     \n",
        "  def mean(self, lbl):\n",
        "    return self._sums[lbl] / self._lbl_Hist[lbl]\n",
        "  \n",
        "  def variance(self, lbl):\n",
        "    sqMean = self.mean(lbl)**2 \n",
        "    var = self._sqSums[lbl] / self._lbl_Hist[lbl] - sqMean \n",
        "    return var if var >= self._minvar else var + self._varRegularizer\n",
        " \n",
        " \n",
        "  def _localLikelihood(self, y, x, lbl):\n",
        "    oldlbl = self._x[y,x]\n",
        "    g = self._image[y,x]\n",
        "    size = self._lbl_Hist[lbl]\n",
        "    sum = self._sums[lbl]\n",
        "    sqsum = self._sqSums[lbl]\n",
        "    if oldlbl != lbl:\n",
        "      size += 1 \n",
        "      sum += g \n",
        "      sqsum += g**2 \n",
        "    mu = sum / size \n",
        "    sigma = (sqsum / size) - mu **2 \n",
        "    if sigma < self._minvar:\n",
        "      sigma += self._varRegularizer\n",
        "    return (g - mu)**2 / (2 * sigma) + np.log(np.sqrt(sigma))\n",
        " \n",
        "  def localLikelihood(self, y, x, lbl):\n",
        "    y,x  = self.adapt(y,x)\n",
        "    return self._localLikelihood(y,x, lbl)\n",
        "  \n",
        "  def _conditionalLocalW(self, y,x):\n",
        "    lbl = self._x[y,x]\n",
        "    sigma = self.variance(lbl)\n",
        "    mu = self.mean(lbl)\n",
        "    g = self._image[y,x]\n",
        "    r =  (g - mu)**2 /(2* sigma) + np.log(np.sqrt(sigma))\n",
        "    return r\n",
        " \n",
        "  def conditionalLocalW(self, y, x):\n",
        "    return self._conditionalLocalW(self, * OnlineMRFMap.adapt(y,x))\n",
        " \n",
        "  def localPriorW(self, y, x):\n",
        "    y, x = self.adapt(y,x)\n",
        "    lbl = self._x[y,x]\n",
        "    return self._localPotential(y,x, lbl)\n",
        " \n",
        "  def _localPotential(self, y,x, lbl):\n",
        "    lP = self._priors[lbl]\n",
        "    for ny, nx in get8neighbors(y,x):\n",
        "      nlbl = self._x[ny, nx]\n",
        "      lP += self._interaction[lbl, nlbl]\n",
        "    return lP\n",
        " \n",
        "  def _measureLocalW(self, y, x, lbl):\n",
        "    return self._localPotential(y,x, lbl) + self._localLikelihood(y, x, lbl)\n",
        " \n",
        "  def measureLocalW(self, y, x, lbl):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._measureLocalW(y,x, lbl)\n",
        " \n",
        "  def _measureLocalFit(self, y, x, lbl):\n",
        "    return np.exp(- self._measureLocalW(y,x, lbl))\n",
        " \n",
        "  def measureLocalFit(self, y, x, lbl):\n",
        "    y, x  = self.adapt(y,x)\n",
        "    return self._measureLocalFit(y,x, lbl)\n",
        "   \n",
        "  def localPotential(self, y, x, lbl):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._localPotential(y,x, lbl)\n",
        " \n",
        " \n",
        " \n",
        " \n",
        "  def _localW(self, y, x):\n",
        "    lbl = self._x[y,x]\n",
        "    lW = self._localPotential(y,x, lbl) + self._conditionalLocalW(y,x)\n",
        "    return lW\n",
        " \n",
        "  def localW(self, y, x):\n",
        "    y, x = self.adapt(y,x)\n",
        "    return self._localW(y,x)\n",
        " \n",
        " \n",
        "  \n",
        "  def changeLabel(self, y, x, lbl):\n",
        "    y, x = self.adapt(y,x)\n",
        "    oldlbl = self._x[y,x]\n",
        "    self._x[y,x] = lbl \n",
        "    self._updatestats(y,x, oldlbl, lbl)\n",
        "  \n",
        "  @property\n",
        "  def size(self):\n",
        "    return (self._image.shape[0] -2) * (self._image.shape[1]-2)\n",
        "  \n",
        "  @property\n",
        "  def labels(self):\n",
        "    return self._x[1:-1, 1:-1].copy()\n",
        "  \n",
        "  @property\n",
        "  def labelCount(self):\n",
        "    return self._labelCount\n",
        " \n",
        "  def localFitnessDistr(self, y,x):\n",
        "    y, x = self.adapt(y,x)\n",
        "    d = [self._measureLocalFit(y,x,lbl) for lbl in range(self.labelCount)]\n",
        "    s = sum(d)\n",
        "    return np.array([v/s for v in d])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CRK1hIgSjbo"
      },
      "source": [
        "# Iterated Conditional Mode \n",
        "Greedy algorithm to optimize and MRF model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM9LH0XzS5fe"
      },
      "source": [
        "## Offline ICM \n",
        "The stats are updated after the genration of a whole configuration \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQcazT3NShui"
      },
      "source": [
        "class OffileICM:\n",
        "  def __init__(self, img, lbls, priors, interaction, max_iter = 1000, epsilon = 1e-4):\n",
        "    self._model = OfflineMRFMap(img, lbls, priors, interaction)\n",
        "    self._current_iteration = 0 \n",
        "    self._maxIter = max_iter \n",
        "    self._iterator = RasterImageIterator(img)\n",
        "    self._stop = False \n",
        "    self._sucess = False \n",
        "    self._eps = epsilon\n",
        "\n",
        "\n",
        "  def best_label(self, y, x):\n",
        "    ref = float('inf')\n",
        "    for lbl in range(self._model.labelCount):\n",
        "      lw = self._model.localW(y,x,lbl)\n",
        "      if lw < ref:\n",
        "        ref = lw \n",
        "        res = lbl \n",
        "    return res \n",
        "\n",
        "\n",
        "\n",
        "  def process_pixel(self, y, x):\n",
        "    lbl = self.best_label(y,x)\n",
        "    if lbl != self._model.label(y,x):\n",
        "      self._changed_labels += 1 \n",
        "      self._model.changeLabel(y,x, lbl)\n",
        "    \n",
        "  def next_iteration(self):\n",
        "    self._lw = self._model.globalW\n",
        "    self._labels = self._model.labels \n",
        "    self._model.init_stats()\n",
        "    self._current_iteration += 1 \n",
        "    self.energies.append(self._model.globalW)\n",
        "    if self._current_iteration > self._maxIter:\n",
        "      self._stop = True \n",
        "    if self._changed_labels <= self._eps or self._model.globalW >= self._lw:\n",
        "      self._stop = True \n",
        "      self._sucess = True \n",
        "\n",
        "  def run(self):\n",
        "    \n",
        "    self.energies = [self._model.globalW]\n",
        "    #logging.info(\" Started : GW = {}\".format(self.energies[-1]))\n",
        "    while not self._stop:\n",
        "      self._changed_labels = 0 \n",
        "      for y, x in self._iterator:\n",
        "        self.process_pixel(y,x)\n",
        "      #logging.info(\" Iteration {} \".format(self._current_iteration))\n",
        "      #logging.info(\" Changed Labels {}\".format(self._changed_labels))\n",
        "      self.next_iteration()\n",
        "    #logging.info(\" Ended : GW = {}\".format(self.energies[-1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKdUkXulTG1a"
      },
      "source": [
        "## OnLine ICM \n",
        "The stats are updated after each site relabeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMShFtQETFsb"
      },
      "source": [
        "class OnlineICM:\n",
        "\n",
        "  @property \n",
        "  def labels(self):\n",
        "    return self._model.labels\n",
        "  \n",
        "  def __init__(self, img, lbls, priors, interacts, maxiter = 1000, eps =3, iter = None):\n",
        "    if iter is None:\n",
        "      iter = RasterImageIterator(img, lbls)\n",
        "    self._model = OnlineMRFMap(img, lbls, priors, interacts)\n",
        "    self._image = img \n",
        "    self._init_x = lbls \n",
        "    self._current_iter = 0 \n",
        "    self._maxiter = maxiter \n",
        "    self._stop = False \n",
        "    self._sucess = False \n",
        "    self._eps = eps \n",
        "    self._iter = iter \n",
        "    self.energies = [self._model.globalW]\n",
        "    self._labels = self._model.labels\n",
        "    self._lastW = self._model.globalW\n",
        "\n",
        "    \n",
        "      \n",
        "  def _bestLabel(self, y, x):\n",
        "    w_ref = np.inf \n",
        "    for lbl in range(self._model.labelCount):\n",
        "      w = self._model.measureLocalW(y,x, lbl)\n",
        "      if w < w_ref:\n",
        "        w_ref = w \n",
        "        lbl_ref = lbl \n",
        "    return lbl_ref\n",
        "      \n",
        "  def _processSite(self, y, x):\n",
        "    lbl = self._bestLabel(y,x)\n",
        "    if lbl != self._model.label(y,x):\n",
        "      self._changedlabels  += 1 \n",
        "      self._model.changeLabel(y, x, lbl)\n",
        "  \n",
        "  def _nextIteration(self):\n",
        "    self._current_iter += 1 \n",
        "    self.energies.append(self._model.globalW)\n",
        "    if self._current_iter > self._maxiter:\n",
        "      self._stop = True \n",
        "    if self._changedlabels <= self._eps:\n",
        "      self._stop = True \n",
        "    \n",
        "    if self._lastW < self.energies[-1]:\n",
        "      self._stop = True \n",
        "      self._sucess = True\n",
        "    else:\n",
        "      self._lastW = self._model.globalW\n",
        "      self._lbls = self._model.labels.copy()\n",
        "\n",
        "  def run(self):\n",
        "    while not self._stop:\n",
        "      self._changedlabels = 0 \n",
        "      for y, x in self._iter: \n",
        "        self._processSite(y, x)\n",
        "      self._nextIteration()\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfvmwi1JYI0a"
      },
      "source": [
        "# AntColony Optiomizer \n",
        "Used ACO to optimize an MRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Y-fZwtYf9Q"
      },
      "source": [
        "## Colony Environment \n",
        "Represents the Environment of the colony \n",
        "- Pheromone Trails\n",
        "- Evaporation Rules \n",
        "- Parameters of the colony "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g7FuEHfTS9r"
      },
      "source": [
        "class Environment:\n",
        "\n",
        "  def __init__(self, img, priors, interacts, tau_0, q0, rho, xi, alpha, beta):\n",
        "    \"\"\"\n",
        "    img = 2d ndarray representing the image pixels \n",
        "    priors = 1d ndarray representing the prior weights \n",
        "    interacts = 2d ndarray containing the interaction weights \n",
        "    tau_0 = (float) initial pheromone qty \n",
        "    q0 = stochasticity \n",
        "    rho = local evaporation rate \n",
        "    xi = global evaporation rate \n",
        "    \"\"\"\n",
        "    self._tau_0 = tau_0\n",
        "    self._q0 = q0 \n",
        "    self._rho = rho \n",
        "    self._xi = xi \n",
        "    self._priors = priors \n",
        "    self._interacts = interacts \n",
        "    self._labelsCount = len(priors)\n",
        "    self._pheromoneTrails = np.full((img.shape + priors.shape), self._tau_0, dtype = np.float64)\n",
        "    self._image = img.copy()\n",
        "    self._alpha = alpha \n",
        "    self._beta = beta \n",
        "    self._hist, _  = np.histogram(img, bins = 256)\n",
        "    self._centers = PeakFinder(img, self._labelsCount).res \n",
        "\n",
        "\n",
        "\n",
        "  def performLocalEvaporation(self, y, x, lbl):\n",
        "    \"\"\"\n",
        "    Applies the local evaporation rule at a specific position on the grid \n",
        "    tau_{y,x,lbl} *=  (1 - rho) \n",
        "    tau_{y,x,lbl'} = (1- rho) * tau_{y,x, lbl}  +  rho / (#Labels - 1) \n",
        "    for all lbl' != lbl \n",
        "    \"\"\"\n",
        "    self._pheromoneTrails[y,x,:] *= (1-self._rho)\n",
        "    self._pheromoneTrails[y,x,:] += (self._rho) / (self._labelsCount-1)\n",
        "    self._pheromoneTrails[y,x,lbl] -= (self._rho) / (self._labelsCount-1)\n",
        "\n",
        "  def pheromone(y,x,lbl):\n",
        "    return self._pheromoneTrails[y,x,lbl]\n",
        "\n",
        "  def performGlobalEvaporation(self, lbls = None):\n",
        "    \"\"\"\n",
        "    Applies the global evaporation rule \n",
        "    tau{y,x,l} *= (1 - xi) for all y, x, l \n",
        "    tau{y,x,lbl} += xi for all y, x if lbl is in the updat solution \n",
        "    \"\"\"\n",
        "    self._pheromoneTrails[:,:,:] *= (1- self._xi)\n",
        "    if lbls is not None:   \n",
        "      h, w = lbls.shape \n",
        "      mask = np.stack([(lbls == i) for i in range(self._priors.size)], axis = -1)\n",
        "      self._pheromoneTrails[mask] += self._xi \n",
        "      #for y in range(h):\n",
        "      #  for x in range(w):\n",
        "      #    self._pheromoneTrails[y,x, lbls[y,x]] += self._xi \n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgOcYarTaxGf"
      },
      "source": [
        "## Ant \n",
        "Each single Ant have its own MRF Map used to generate the heuristic info and uses the pheromone trails for label desirability "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pt-dNdhawGZ"
      },
      "source": [
        "class Ant:\n",
        "  def __init__(self, env, queen, iter_cls = None):\n",
        "    self._env = env \n",
        "    self._queen = queen \n",
        "    if iter_cls is None:\n",
        "      self._iter_cls = Z3DImageIterator\n",
        "    self._init_stats()\n",
        "\n",
        "  def _init_stats(self):\n",
        "    import random \n",
        "    self._centers = []\n",
        "    self._priorsWeights = []\n",
        "    self._means = []\n",
        "    self._vars = []\n",
        "    v = (256/self._env._labelsCount)**2 \n",
        "    ctrs = self._env._centers.copy() \n",
        "    for l in range(self._env._labelsCount):\n",
        "      idx = random.randrange(len(ctrs))\n",
        "      self._centers.append(ctrs[idx])\n",
        "      ctrs.pop(idx)\n",
        "      self._priorsWeights.append(1/self._env._labelsCount)\n",
        "      self._vars.append(v)\n",
        "      self._means.append(self._centers[-1])\n",
        "    self._means.sort()\n",
        "    img = self._env._image \n",
        "    em = EMGMM(self._priorsWeights, self._means, self._vars)\n",
        "    em.fit(self._env._hist)\n",
        "    self._lbls = em.predict(img)\n",
        "    self._map = OnlineMRFMap(img, self._lbls, self._env._priors, self._env._interacts)\n",
        "    self._iter = self._iter_cls(img, self._lbls)\n",
        "\n",
        "  def _chooseLabel(self, y, x):\n",
        "    import random \n",
        "    p = random.random()\n",
        "    h = self._map.localFitnessDistr(y, x)\n",
        "    weights = self._env._pheromoneTrails[y,x,:] ** self._env._alpha * h ** self._env._beta \n",
        "    if p <= self._env._q0:\n",
        "      #greedy bevahior \n",
        "      label = weights.argmax()\n",
        "    else: \n",
        "      #stochastic behavior \n",
        "      label, *_ = random.choices(range(self._env._labelsCount), weights)\n",
        "    self._map.changeLabel(y,x, label)\n",
        "    self._env.performLocalEvaporation(y,x, label)\n",
        "\n",
        "  def buildLabeling(self, do_local_search):\n",
        "    for y,x in self._iter:\n",
        "      self._chooseLabel(y,x)\n",
        "    if do_local_search:\n",
        "      icm = OnlineICM(self._env._image, self._map.labels, self._env._priors, self._env._interacts, self._queen._ls_iter, 0, self._iter)\n",
        "      icm.run()\n",
        "      self._map = icm._model\n",
        "      self._local_done = icm._current_iter\n",
        "    else:\n",
        "      self._local_done = 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4tA71JibRNo"
      },
      "source": [
        "## Queen \n",
        "The Queen Manages The Execution of the algorithm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUioEOJbbQZP"
      },
      "source": [
        "from enum import Enum\n",
        "class UpdateMode(Enum):\n",
        "  BestSoFar = 0\n",
        "  IterationBest = 1 \n",
        "  MixedUpdate = 2 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lzCXKkRbh0U"
      },
      "source": [
        "class Queen:\n",
        "  def __init__(self, nb_ants, env, nb_iter, ls_max_iter, do_local_search, update_mode, frequence ):\n",
        "    self._freq = frequence \n",
        "    self._mode = update_mode \n",
        "    self._ls_iter = ls_max_iter \n",
        "    self._env = env \n",
        "    self._ants = [Ant(env, self) for _ in range(nb_ants)]\n",
        "    self._nb_iter = nb_iter \n",
        "    self._nb_ants = nb_ants \n",
        "    self._do_ls = do_local_search\n",
        "    self._bestW = np.inf \n",
        "  \n",
        "  \n",
        "  def _pickBestLabeling(self):\n",
        "    energies = [a._map.globalW for a in self._ants]\n",
        "    local_iters = [a._local_done  for a in self._ants]\n",
        "    bestW = max(energies)\n",
        "    bestIdx = energies.index(bestW)\n",
        "    if self._bestW > bestW:\n",
        "      self._bestW = bestW\n",
        "      self._bestLabeling = self._ants[bestIdx]._map.labels \n",
        "    if self._mode == UpdateMode.BestSoFar:\n",
        "      self._env.performGlobalEvaporation(self._bestLabeling)\n",
        "    elif self._mode == UpdateMode.IterationBest:\n",
        "      self._env.performGlobalEvaporation(self._ants[bestIdx]._map.labels)\n",
        "    elif self._nb_iter  % self._freq == 0:\n",
        "      self._env.performGlobalEvaporation(self._bestLabeling)\n",
        "    else: \n",
        "      self._env.performGlobalEvaporation(self._ants[bestIdx]._map.labels)\n",
        "    \n",
        "\n",
        "  \n",
        "  def _main(self):\n",
        "    while self._nb_iter != 0:\n",
        "      for a in self._ants: \n",
        "        a.buildLabeling(self._do_ls)\n",
        "      self._pickBestLabeling()\n",
        "      self._nb_iter -= 1\n",
        "    return self._bestLabeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-UN-zb0bmcY"
      },
      "source": [
        "## The ACO Algorithm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJn5eM6hblmV"
      },
      "source": [
        "class ACOICMMRF:\n",
        "  def __init__(self, nb_lbl, nb_ants, nb_iter, img, priors, interacts, rho, xi, \\\n",
        "               alpha, beta, q0, do_ls, ls_max_iter, ground = None):\n",
        "    tau_0 = 1/ nb_lbl\n",
        "    self._env = Environment(img, priors, interacts, tau_0, q0, rho, xi, alpha, beta)\n",
        "    self._queen = Queen(nb_ants, self._env, nb_iter, do_ls, ls_max_iter, UpdateMode.BestSoFar, 1)\n",
        "  \n",
        "  def run(self):\n",
        "    self.labels = self._queen._main()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj3NrqEybv1F"
      },
      "source": [
        "# Evaluation Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETjB6KqFb1A5"
      },
      "source": [
        "## Unsupervised Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCQMzL_mbtoW"
      },
      "source": [
        "def Borsotti(img, lbls, ret_info = False, connected = False):\n",
        "  from skimage.measure import label\n",
        "  from numpy import sqrt, log\n",
        "  min_lbl , max_lbl = lbls.min(), lbls.max()\n",
        "  #lbls += min_lbl +1 # no background pixel split everything \n",
        "  #into connected components \n",
        "  if not connected:\n",
        "    cc_lbls  = label(lbls, background=-1)\n",
        "  else: \n",
        "    cc_lbls  = lbls \n",
        "  min_lbl, max_lbl = cc_lbls.min(), cc_lbls.max()\n",
        "  num_lbls = len(set(cc_lbls.flat))\n",
        "  masks = {v:cc_lbls == v  for v in range(min_lbl, max_lbl+1)}\n",
        "  areas = {v:masks[v].sum() for v in masks}\n",
        "  errors = {v:img[masks[v]].std() for v in masks}\n",
        "  lst_areas = list(areas.values())\n",
        "  d = {v:lst_areas.count(v) for v in set(lst_areas)} \n",
        "  print( {\"errors\":errors, \"areas\":areas,  \"region/area\":d})\n",
        "  try:\n",
        "        s =  1/(1000 * img.size) * np.sqrt(num_lbls+1) *\\\n",
        "   sum(errors[i]**2/ (1+ log(areas[i])) + (d[areas[i]]/areas[i])**2 for i in masks) \n",
        "  except Exception as e:\n",
        "    print(\"error  : \", {\"errors\":errors, \"areas\":areas, \"masks\":masks, \"region/area\":d})\n",
        "    print(e)\n",
        "    \n",
        "  if not ret_info:\n",
        "    return s \n",
        "  else: \n",
        "    return {\"metric\":s, \"errors\":errors, \"areas\":areas, \"masks\":masks, \"region/area\":d}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p399Ti-5b9pW"
      },
      "source": [
        "## Supervised Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy_alsk9OH4D"
      },
      "source": [
        "Preprocess the image to produce a binary filter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiiOCXW5OHNq"
      },
      "source": [
        "def postprocess(lbls, gt):\n",
        "  \"\"\"\n",
        "  The groundTruth a binary mask \n",
        "  lbls could be a formed by more than 2 labels an arbitrary order, representing \n",
        "  a connected regions  extracted from the segmented image.  \n",
        "  The function returns a binary mask that matches the groudTruth gt as close as possible, \n",
        "  by applying the following processing \n",
        "  for each label in lbls \n",
        "    nb0 = # of pixels in the intersection between the region associated to label and the background (0)\n",
        "    nb1 = # of pixels in the intersection between the region associated to label and the foreground (1)\n",
        "    associate label to (0 : background) if nb0 > nb1, otherwise associate label to (1: foreground)  \n",
        "  \"\"\"\n",
        "  from skimage.measure import label \n",
        "  lbls = label(lbls, background = -1)\n",
        "  gt = gt.astype(np.bool)\n",
        "  output = np.zeros(gt.shape, dtype = np.bool)\n",
        "  min_lbl, max_lbl = lbls.min(), lbls.max()\n",
        "  for label in range(min_lbl, max_lbl):\n",
        "    m = lbls == label\n",
        "    nb0 = (m&(~gt)).sum() \n",
        "    nb1 = (m&gt).sum()\n",
        "    if nb1 >= nb0:\n",
        "      output[m] = 1 \n",
        "    else: \n",
        "      output[m] = 0 \n",
        "  return output  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuEG-BTgb7C1"
      },
      "source": [
        "def accuracy_metric(gt, output, normalize = True):\n",
        "  from sklearn.metrics import accuracy_score \n",
        "  return accuracy_score(gt.ravel(), output.ravel(), normalize = normalize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAhjnjlDcHSj"
      },
      "source": [
        "def dice_metric(gt, output, pos_label = 1, average = \"weighted\"):\n",
        "  from sklearn.metrics import f1_score \n",
        "  return f1_score(gt.ravel(), output.ravel(), pos_label = pos_label, average = average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewSWca4KvqH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkjjQkLMcMP7"
      },
      "source": [
        "# Benchmark Algorithms "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKlWvsfcTtX"
      },
      "source": [
        "## WaterShed V1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDtLxGSucKN1"
      },
      "source": [
        "def WaterShed1(img, file = None):\n",
        "  from skimage.segmentation import watershed \n",
        "  from skimage.filters import sobel \n",
        "  img = sobel(img)\n",
        "  labels =  watershed(img)\n",
        "  if file is not None:\n",
        "    file.write(str(locals()))\n",
        "  return labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHfWL2ttciTP"
      },
      "source": [
        "## WaterShed 2\n",
        "https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_marked_watershed.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCyx0Er8cfex"
      },
      "source": [
        "def WaterShed2(image, file = None):\n",
        "  from scipy import ndimage as ndi\n",
        "  from skimage.morphology import disk\n",
        "  from skimage.segmentation import watershed\n",
        "  from skimage import data\n",
        "  from skimage.filters import rank\n",
        "  from skimage.util import img_as_ubyte\n",
        "  image = img_as_ubyte(image)\n",
        "  # denoise image\n",
        "  denoised = rank.median(image, disk(2))\n",
        "  # find continuous region (low gradient -\n",
        "  # where less than 10 for this image) --> markers\n",
        "  # disk(5) is used here to get a more smooth image\n",
        "  markers = rank.gradient(denoised, disk(5)) < 10\n",
        "  markers = ndi.label(markers)[0]\n",
        "  # local gradient (disk(2) is used to keep edges thin)\n",
        "  gradient = rank.gradient(denoised, disk(2))\n",
        "  # process the watershed\n",
        "  labels = watershed(gradient, markers)\n",
        "  if file is not None: \n",
        "    file.write(str(locals()))\n",
        "  return labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB9ZRCSqfRbm"
      },
      "source": [
        "## MeanShift Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4_Z0O5hfIy8"
      },
      "source": [
        "def MeanShift(img, file = None, sdf = 10):\n",
        "  from sklearn.cluster import MeanShift\n",
        "  from skimage.transform import resize  \n",
        "  ms =   MeanShift()\n",
        "  h, w  = img.shape \n",
        "  simg = resize(img,(h//sdf, w//sdf), preserve_range = True )\n",
        "  ms.fit(simg.reshape((-1,1)))\n",
        "  labels =  ms.predict(img.reshape((-1,1))).reshape(img.shape)\n",
        "  if file is not None:\n",
        "    file.write(str(locals()) + \"\\n\")\n",
        "    file.write(str(ms.__dict__) + \"\\n\")\n",
        "  return labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzK4MPzIfd2e"
      },
      "source": [
        "## Normalized GraphCut\n",
        "https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_ncut.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBymkdi_fZM9"
      },
      "source": [
        "def NormalizedCut(img, factor = 30, file = None):\n",
        "  from skimage import data, segmentation, color\n",
        "  from skimage.future import graph\n",
        "  from matplotlib import pyplot as plt\n",
        "  from skimage.util import img_as_ubyte \n",
        "  start = time.perf_counter()\n",
        "  img = img_as_ubyte(img)\n",
        "  #print(img.dtype)\n",
        "  #img = img.astype(np.double)\n",
        "  #print(img.min(), img.maaax())\n",
        "  labels1 = segmentation.slic(img, img.size// factor)\n",
        "  #out1 = color.label2rgb(labels1, img, kind='avg', bg_label=0)\n",
        "  #plt.imshow(labels1, \"gray\")\n",
        "  #plt.show()\n",
        "  g = graph.rag_mean_color(img, labels1, mode='similarity')\n",
        "  labels2 = graph.cut_normalized(labels1, g)\n",
        "  if file is not None: \n",
        "    file.write(str(locals()) + \"\\n\")\n",
        "  return labels2 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0TAL_OcOrDT"
      },
      "source": [
        "# Segmentation Algorithms as simple function img --> labels  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCQjsHvI47z"
      },
      "source": [
        "def em(img, nb_reg = 2, file = None): \n",
        "  em = EMGMM(1/nb_reg * np.ones((nb_reg,)) , np.arange(0,256, 256/nb_reg), 50 *  np.ones((nb_reg)))\n",
        "  hist, _  = np.histogram(img, bins = 256)\n",
        "  em.fit(hist)\n",
        "  if file is not None:\n",
        "    file.write(str(em.__dict__) + \"\\n\")\n",
        "  return em.predict(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6pS862IxRhr"
      },
      "source": [
        "def sk_em(img, nb_reg = 2, file = None):\n",
        "  from sklearn.mixture import GaussianMixture \n",
        "  gmm = GaussianMixture(n_components=nb_reg)\n",
        "  gmm.fit(X = img.reshape(-1,1))\n",
        "  lbls = gmm.predict(img.reshape(-1,1)).reshape(img.shape)\n",
        "  if file is not None:\n",
        "    file.write(str(gmm.__dict__) + \"\\n\")\n",
        "  return lbls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQBXlsvAxXXW"
      },
      "source": [
        "def kmeans(img, nb_reg = 2, sdf = 10, file = None):\n",
        "  from sklearn.cluster import KMeans\n",
        "  from skimage.transform import resize  \n",
        "  km =   KMeans(n_clusters = nb_reg)\n",
        "  h, w  = img.shape \n",
        "  simg = resize(img,(h//sdf, w//sdf), preserve_range = True )\n",
        "  km.fit(simg.reshape((-1,1)))\n",
        "  labels =  km.predict(img.reshape((-1,1))).reshape(img.shape)\n",
        "  if file is not None:\n",
        "    file.write(str(locals()) + \"\\n\")\n",
        "    file.write(str(km.__dict__) + \"\\n\")\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvSCJrR5ftDH"
      },
      "source": [
        "def offline_icm(img, nb_reg = 2, priors = None, interaction= None, max_iter = 10, file = None):\n",
        "  if priors is None: \n",
        "    priors = np.zeros((nb_reg,))\n",
        "  if interaction is None:\n",
        "    interaction = np.ones((nb_reg, nb_reg))- np.identity(nb_reg)\n",
        "  lbls = em(img, nb_reg)\n",
        "  icm = OffileICM(img, lbls , priors, interaction, max_iter = max_iter)\n",
        "  icm.run()\n",
        "  if file is not None:\n",
        "    file.write(str(icm.__dict__) + \"\\n\")\n",
        "    file.write(str(icm._model.__dict__) + \"\\n\")\n",
        "  return icm._model.labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LpdMGMIMZkU"
      },
      "source": [
        "def online_icm(img, nb_reg = 2, priors = None, interaction = None, max_iter = 10, iter = None, file = None):\n",
        "  if priors is None: \n",
        "    priors = np.zeros((nb_reg,))\n",
        "  if interaction is None:\n",
        "    interaction = np.ones((nb_reg, nb_reg)) - np.identity(nb_reg)\n",
        "  if iter is None:\n",
        "    iter = Hilbert3DImageIterator(img)\n",
        "    lbls = em(img, nb_reg)\n",
        "  icm = OnlineICM(img, lbls, priors, interaction, iter = iter, maxiter=max_iter)\n",
        "  icm.run()\n",
        "  if file is not None:\n",
        "    file.write(str(icm.__dict__) + \"\\n\")\n",
        "    file.write(str(icm._model.__dict__) + \"\\n\")\n",
        "  return icm._model.labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORTSaRwDO7jh"
      },
      "source": [
        "def aco_icm_mrf(img, nb_reg = 2, nb_ants = 2, nb_iter = 10, priors = None, \n",
        "                interaction = None, rho = 0.01, xi = 0.05, alpha = 2, beta = 1, \n",
        "                q0 = 0.5, perf_local = True, local_iter = 10, file = None):\n",
        "  if priors is None: \n",
        "    priors = np.zeros((nb_reg,))\n",
        "  if interaction is None:\n",
        "    interaction = np.ones((nb_reg, nb_reg)) - np.identity(nb_reg)\n",
        "  aco = ACOICMMRF(nb_reg, nb_ants, nb_iter, img, priors, interaction, rho, xi, alpha, beta , q0, perf_local, local_iter)\n",
        "  aco.run()\n",
        "  if file is not None:\n",
        "    file.write(str(aco.__dict__) + \"\\n\")\n",
        "    file.write(str(aco._env.__dict__) + \"\\n\")\n",
        "    file.write(str(aco._queen.__dict__) + \"\\n\")\n",
        "  return aco.labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuWWWmN5Ub8f"
      },
      "source": [
        "# Function that takes the number of regions -- > dict where : \n",
        "  - each key is an str indicating the algorithm name (used to make the directory of the result) \n",
        "  - each value is a function that takes an image and returns \n",
        "  the labeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keELp21JU1yL"
      },
      "source": [
        "def algs(nb_reg = 2):\n",
        "  return {\n",
        "      \"HIST_EM\" : lambda img, file = None : em(img, nb_reg, file = file),\n",
        "      \"ONLINE_ICM\" : lambda img, file = None  : online_icm(img, nb_reg, file = file),\n",
        "      \"OFFLINE_ICM\" : lambda img, file = None : offline_icm(img, nb_reg, file = file), \n",
        "      \"ACO_ICM_MRF\" : lambda img, file = None : aco_icm_mrf(img, nb_reg, file = file),\n",
        "      \"EM\" : lambda img, file = None : sk_em(img, nb_reg, file = file), \n",
        "      \"KMEANS\" : lambda img, file = None : kmeans(img, nb_reg, file = file)\n",
        " \n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX4PnriSVNa7"
      },
      "source": [
        "benchmarks = {\"Watershed1\" : lambda img, file = None : WaterShed1(img, file = file), \n",
        "              \"Watershed2\": lambda img, file = None : WaterShed2(img, file = file), \n",
        "              \"MeanShift\": lambda img, file = None : MeanShift(img, file = file), \n",
        "              \"NormalizedGraphCut\": lambda img, file = None : NormalizedCut(img, file = file)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPg_DjuFJmXk",
        "outputId": "36fdddc8-1714-464b-cd54-fcac0aef4ca1"
      },
      "source": [
        "! unzip /content/Weizmann_Seg_DB_1obj.ZIP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Weizmann_Seg_DB_1obj.ZIP\n",
            "replace 1obj/0677845-r1-067-32_a/human_seg/0677845-r1-067-32_a_7.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYSEBriCJ3Hw"
      },
      "source": [
        "import shutil\n",
        "\n",
        "#Nnshutil.rmtree('/content/1obj')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUAxDO0iEzpz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE7WrwE7J3K2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi8i-VsIKDmY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDyrPMaOJ91e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSoOUAbLJ94w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue6QHQl9J9NA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQJ77JnbJ9RV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLqxUBf1Oym8"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXJ046YDb5pM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZT2i5KWb-xK"
      },
      "source": [
        "gray_dir = \"src_bw\"\n",
        "file_ext = \".png\"\n",
        "params_file = \"params.txt\"\n",
        "array_file = \"labels.npy\"\n",
        "imgs = []\n",
        "for spath in glob.glob(r\"/content/1obj/*\"):\n",
        "  if os.path.isdir(spath):\n",
        "    img_name = os.path.basename(spath) + file_ext\n",
        "    img_path = os.path.join(spath, gray_dir, img_name)\n",
        "    img = imread(img_path)\n",
        "    hist, _ = np.histogram(img, bins = 256)\n",
        "    for dir_name, fct in benchmarks.items():\n",
        "      dir_path = os.path.join(spath, dir_name)\n",
        "      os.mkdir(dir_path)\n",
        "      params_path = os.path.join(dir_path, params_file)\n",
        "      file = open(params_path, \"w\")\n",
        "      start = time.perf_counter()\n",
        "      labels = fct(img,file)\n",
        "      end = time.perf_counter()\n",
        "      file.write(\" duration : {}\".format(end - start))\n",
        "      file.close()\n",
        "      array_path = os.path.join(dir_path, array_file)\n",
        "      np.save(array_path, labels)\n",
        "      labels_path  = os.path.join(dir_path, img_name)\n",
        "      plt.imsave(labels_path, labels, cmap = 'gray')   \n",
        "    for nb_reg in range(2, 5):\n",
        "      alg_dict = algs(nb_reg)\n",
        "      for name, fct in alg_dict.items():\n",
        "        dir_name = \"{}  {}\".format(name, nb_reg)\n",
        "        dir_path = os.path.join(spath, dir_name)\n",
        "        os.mkdir(dir_path)\n",
        "        params_path = os.path.join(dir_path, params_file)\n",
        "        file = open(params_path, \"w\")\n",
        "        start = time.perf_counter()\n",
        "        labels = fct(img,file)\n",
        "        end = time.perf_counter()\n",
        "        file.write(\" duration : {}\".format(end - start))\n",
        "        file.close()\n",
        "        array_path = os.path.join(dir_path, array_file)\n",
        "        np.save(array_path, labels)\n",
        "        labels_path  = os.path.join(dir_path, img_name)\n",
        "        plt.imsave(labels_path, labels, cmap = 'gray')   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZrlIcSh9HK"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import time \n",
        "import multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm \n",
        "\n",
        "def launch_segmentation(fct, img, spath, dir_name, params_file, array_file, img_name):\n",
        "  dir_path = os.path.join(spath, dir_name)\n",
        "  params_path = os.path.join(dir_path, params_file)\n",
        "  array_path = os.path.join(dir_path, array_file)\n",
        "  labels_path  = os.path.join(dir_path, img_name)\n",
        "  if os.path.exists(labels_path):\n",
        "    return \n",
        "  elif not os.path.exists(dir_path):\n",
        "    os.mkdir(dir_path)\n",
        "  file = open(params_path, \"w\")\n",
        "  start = time.perf_counter()\n",
        "  labels = fct(img,file)\n",
        "  end = time.perf_counter()\n",
        "  file.write(\"\\nduration : {}\".format(end - start))\n",
        "  file.close()\n",
        "  np.save(array_path, labels)\n",
        "  labels_path  = os.path.join(dir_path, img_name)\n",
        "  plt.imsave(labels_path, labels, cmap = 'gray')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1LXRf5_6Lm3"
      },
      "source": [
        "def process_directory(spath, gray_dir, file_ext, params_file, array_file):\n",
        "  img_name = os.path.basename(spath) + file_ext\n",
        "  img_path = os.path.join(spath, gray_dir, img_name)\n",
        "  img = imread(img_path)\n",
        "  hist, _ = np.histogram(img, bins = 256)\n",
        "  for dir_name, fct in job_dict.items():\n",
        "    launch_segmentation(fct, img, spath, dir_name, params_file, array_file, img_name) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLh0bO-F6Gmq",
        "outputId": "b31ea93d-4424-466f-9ed3-d75e26598a1f"
      },
      "source": [
        "gray_dir = \"src_bw\"\n",
        "file_ext = \".png\"\n",
        "params_file = \"params.txt\"\n",
        "array_file = \"labels.npy\"\n",
        "job_dict = benchmarks.copy()\n",
        "for nb_reg in range(2,5):\n",
        "  job_dict.update({\"{}  {}\".format(name, nb_reg):fct for name, fct in algs(nb_reg).items()})\n",
        "inputs = tqdm(spath for spath in glob.glob(r\"/content/1obj/*\") if os.path.isdir(spath))\n",
        "p = Parallel(-1)\n",
        "p(delayed(process_directory)(spath, gray_dir, file_ext, params_file, array_file)\\\n",
        "  for spath in inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHtwOr2ykmBx"
      },
      "source": [
        "import multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH1A8PJNktUx",
        "outputId": "7976b710-8c4f-4947-bf6a-71d7cdba750e"
      },
      "source": [
        "gray_dir = \"src_bw\"\n",
        "file_ext = \".png\"\n",
        "params_file = \"params.txt\"\n",
        "array_file = \"labels.npy\"\n",
        "imgs = []\n",
        "job_dict = benchmarks.copy()\n",
        "for nb_reg in range(2,5):\n",
        "  job_dict.update({\"{}  {}\".format(name, nb_reg):fct\\\n",
        "                   for name, fct in algs(nb_reg).items()})\n",
        "inputs = tqdm(job_dict.items())\n",
        "for spath in glob.glob(r\"/content/1obj/*\"):\n",
        "  if os.path.isdir(spath):\n",
        "    img_name = os.path.basename(spath) + file_ext\n",
        "    img_path = os.path.join(spath, gray_dir, img_name)\n",
        "    img = imread(img_path)\n",
        "    hist, _ = np.histogram(img, bins = 256)\n",
        "    p = Parallel(-1)\n",
        "    p(delayed(launch_segmentation)(fct, img, spath, dir_name, params_file, array_file, img_name) \\\n",
        "              for dir_name, fct in inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiZ7kTwgh2Jf"
      },
      "source": [
        "gray_dir = \"src_bw\"\n",
        "file_ext = \".png\"\n",
        "params_file = \"params.txt\"\n",
        "array_file = \"labels.npy\"\n",
        "imgs = []\n",
        "for spath in glob.glob(r\"/content/1obj/*\"):\n",
        "  if os.path.isdir(spath):\n",
        "    img_name = os.path.basename(spath) + file_ext\n",
        "    img_path = os.path.join(spath, gray_dir, img_name)\n",
        "    img = imread(img_path)\n",
        "    hist, _ = np.histogram(img, bins = 256)\n",
        "    for dir_name, fct in benchmarks.items():\n",
        "        launch_segmentation(fct, img, spath, dir_name, params_file, array_file, img_name)\n",
        "    for nb_reg in range(2, 5):\n",
        "      alg_dict = algs(nb_reg)\n",
        "      for name, fct in alg_dict.items():\n",
        "        dir_name = \"{}  {}\".format(name, nb_reg)\n",
        "        launch_segmentation(fct, img, spath, dir_name, params_file, array_file, img_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3rWj3cCMnfY"
      },
      "source": [
        "gray_dir = \"src_bw\"\n",
        "gt_dir = \"human_seg\"\n",
        "file_ext = \".png\"\n",
        "params_file = \"params.txt\"\n",
        "array_file = \"labels.npy\"\n",
        "prefixes = {\"ACO_ICM_MRF\", \"HIST_EM\", \"OFFLINE_ICM\", \"ONLINE_ICM\"}\n",
        "file_name = \"report.txt\"\n",
        "borsotti = \"BORSOTTI\"\n",
        "acc = \"ACCURACY\"\n",
        "dice = \"DICE\"\n",
        "report = {}\n",
        "for spath in glob.glob(r\"1obj/*\"):\n",
        "    if os.path.isdir(spath):\n",
        "        img_name = os.path.basename(spath)\n",
        "        img_stats = {}\n",
        "        report[img_name] = img_stats \n",
        "        gt_path = os.path.join(spath, gt_dir)\n",
        "        gts  = []\n",
        "        for img_path in glob.glob(gt_path + \"/*.png\"):\n",
        "            img = plt.imread(img_path)\n",
        "            gts.append((img == [1,0,0])[:,:,0])\n",
        "        for rpath in glob.glob(spath + \"/*\"):\n",
        "            if os.path.isdir(spath):\n",
        "                folder_name = os.path.basename(rpath)\n",
        "                if any(folder_name.startswith(pre) for pre in prefixes):\n",
        "                  alg_stats = {}\n",
        "                  img_stats[folder_name] = alg_stats \n",
        "                  labels_path = os.path.join(rpath, array_file)\n",
        "                  if not os.path.exists(labels_path):\n",
        "                    continue \n",
        "                  labels = np.load(labels_path)\n",
        "                  alg_stats[borsotti] = Borsotti(img, labels)\n",
        "                  x = Borsotti(img, labels, connected = False, ret_info=True)\n",
        "                  print(x)\n",
        "                  x = input(folder_name)\n",
        "                  for index, gt in enumerate(gts):\n",
        "                    lbl = postprocess(labels, gt)\n",
        "                    acc_key = \"{}{}\".format(acc, index)\n",
        "                    dice_key = \"{}{}\".format(dice, index)\n",
        "           \n",
        "                    alg_stats[acc_key] = accuracy_metric(gt, lbl) \n",
        "\n",
        "                    alg_stats[dice_key] = dice_metric(gt, lbl)\n",
        "                if any(folder_name.startswith(pre) for pre in benchmarks):\n",
        "                  alg_stats = {}\n",
        "                  img_stats[folder_name] = alg_stats \n",
        "                  labels_path = os.path.join(rpath, array_file)\n",
        "                  if not os.path.exists(labels_path):\n",
        "                    continue \n",
        "                  labels = np.load(labels_path)\n",
        "                  alg_stats[borsotti] = Borsotti(img, labels, connected= True)\n",
        "                  x = Borsotti(img, labels, connected = True, ret_info=True)\n",
        "                  print(x)\n",
        "                  x = input(folder_name)\n",
        "                  for index, gt in enumerate(gts):\n",
        "                    lbl = postprocess(labels, gt)\n",
        "                    alg_stats[acc + str(index)] = accuracy_metric(gt, lbl) \n",
        "                    alg_stats[dice + str(index)] = dice_metric(gt, lbl)\n",
        "\n",
        "                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "D8BUkTf6d7p1",
        "outputId": "b8a7dd11-c3a6-4d29-9d40-8b6dace0a523"
      },
      "source": [
        "job_dict = benchmarks.copy()\n",
        "for nb_reg in range(2,5):\n",
        "  job_dict.update({\"{}  {}\".format(name, nb_reg):fct for name, fct in algs(nb_reg).items()})\n",
        "gray_dir = \"src_bw\"\n",
        "gt_dir = \"human_seg\"\n",
        "file_ext = \".png\"\n",
        "params_file = \"params.txt\"\n",
        "array_file = \"labels.npy\"\n",
        "prefixes = set(job_dict) - set(benchmarks)\n",
        "file_name = \"report.txt\"\n",
        "borsotti = \"BORSOTTI\"\n",
        "acc = \"ACCURACY\"\n",
        "dice = \"DICE\"\n",
        "report = {}\n",
        "for spath in glob.glob(r\"1obj/*\"):\n",
        "    if os.path.isdir(spath):\n",
        "        img_name = os.path.basename(spath)\n",
        "        img_stats = {}\n",
        "        report[img_name] = img_stats \n",
        "        gt_path = os.path.join(spath, gt_dir)\n",
        "        gts  = []\n",
        "        for img_path in glob.glob(gt_path + \"/*.png\"):\n",
        "            img = plt.imread(img_path)\n",
        "            gts.append((img == [1,0,0])[:,:,0])\n",
        "        for rpath in glob.glob(spath + \"/*\"):\n",
        "            if os.path.isdir(spath):\n",
        "                folder_name = os.path.basename(rpath)\n",
        "                if any(folder_name.startswith(pre) for pre in prefixes):\n",
        "                  alg_stats = {}\n",
        "                  img_stats[folder_name] = alg_stats \n",
        "                  labels_path = os.path.join(rpath, array_file)\n",
        "                  if not os.path.exists(labels_path):\n",
        "                    continue \n",
        "                  labels = np.load(labels_path, allow_pickle=True)\n",
        "                  alg_stats[borsotti] = Borsotti(img, labels)\n",
        "                 \n",
        "                 \n",
        "                  for index, gt in enumerate(gts):\n",
        "                    lbl = postprocess(labels, gt)\n",
        "                    acc_key = \"{}{}\".format(acc, index)\n",
        "                    dice_key = \"{}{}\".format(dice, index)\n",
        "                    alg_stats[acc_key] = accuracy_metric(gt, lbl) \n",
        "                    alg_stats[dice_key] = dice_metric(gt, lbl)\n",
        "                if any(folder_name.startswith(pre) for pre in benchmarks):\n",
        "                  alg_stats = {}\n",
        "                  img_stats[folder_name] = alg_stats \n",
        "                  labels_path = os.path.join(rpath, array_file)\n",
        "                  if not os.path.exists(labels_path):\n",
        "                    continue \n",
        "                  labels = np.load(labels_path, allow_pickle=True)\n",
        "                  alg_stats[borsotti] = Borsotti(img, labels, connected= True)\n",
        "                  for index, gt in enumerate(gts):\n",
        "                    lbl = postprocess(labels, gt)\n",
        "                    alg_stats[acc + str(index)] = accuracy_metric(gt, lbl) \n",
        "                    alg_stats[dice + str(index)] = dice_metric(gt, lbl)\n",
        "\n",
        "                  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2fa7083bf465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnb_reg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mjob_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"{}  {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfct\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgray_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"src_bw\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgt_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"human_seg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'benchmarks' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13QzTYL0GJG8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wep-Uj5_rq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac025db-fbe3-4c08-b705-988fb0f92f24"
      },
      "source": [
        "report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-5-oZFCEjqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d7a287-23c2-4233-b09b-df1d233169c0"
      },
      "source": [
        "!zip -r /content/res1obj.zip /content/1obj/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: name not matched: /content/1obj/\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/res1obj.zip . -i /content/1obj/)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JaiGkvBCobE",
        "outputId": "57e9b178-4749-4e80-e3e3-f6ff06371320"
      },
      "source": [
        "from google.colab import files \n",
        "files.download(\"/content/res1obj.zip \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-a9a450ac96c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/res1obj.zip \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/res1obj.zip "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzr1hxoyDD8w"
      },
      "source": [
        "import multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "num_cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHTUriOpE5ke"
      },
      "source": [
        "num_cores\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo22JenDE98A"
      },
      "source": [
        "import os\n",
        "def lauch_segmentation(fct, img, spath, dir_name, params_file, array_file, img_name):\n",
        "  dir_path = os.path.join(spath, dir_name)\n",
        "  params_path = os.path.join(dir_path, params_file)\n",
        "  array_path = os.path.join(dir_path, array_file)\n",
        "  labels_path  = os.path.join(dir_path, img_name)\n",
        "  if os.path.exists(labels_path):\n",
        "    return \n",
        "  elif not os.path.exists(dir_path):\n",
        "    os.mkdir(dir_path)\n",
        "  file = open(params_path, \"w\")\n",
        "  start = time.perf_counter()\n",
        "  labels = fct(img,file)\n",
        "  end = time.perf_counter()\n",
        "  file.write(\"\\nduration : {}\".format(end - start))\n",
        "  file.close()\n",
        "  np.save(array_path, labels)\n",
        "  labels_path  = os.path.join(dir_path, img_name)\n",
        "  plt.imsave(labels_path, labels, cmap = 'gray')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXjuV37OHK_e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
